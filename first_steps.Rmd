---
title: "FECR - Use examples"
output: 
  html_document: 
    toc: true
    toc_depth: 3
    toc_float:
      collapsed: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
In this page we show of to perform FECR tests - Fecal Egg Count Reduction tests - from individual
values of EPG: egg per gram of feces/fecal sediment.   

Implemented methods refer to Cabaret & Berrag (2004), as well as our method that improve their
proposed best approach.    

We demonstrate the use of these methods on simulated data, as well as the toy example presented in 
this reference article.

# Use example on simulated data
## EPG simulation
We simulate EPG values (one per individual) by drawing from poisson distributions as follow:

```{r random init}
library(FECR)

set.seed(42)

# Generate random EPG values, in the simple case of equal sample size
T1 <- rpois(50,100);T1.mean <- mean(T1)
T2 <- rpois(50,10);T2.mean <- mean(T2)
C1 <- rpois(50,100);C1.mean <- mean(C1)
C2 <- rpois(50,90);C2.mean <- mean(C2)
```
## FECR calculations
### When sample size is the same
The `FECR()` function of this `FECR` package takes vectors of EPG values as arguments `T1`, `T2`,
`C1`, and `C2`.

From these values, you can specify a method between `"Kochapakdee"`, `"Dash"`, `"Coles"`,
`"Cabaret1"`, `"Cabaret2"`.

Note that some of these methods do not require all arguments: for these methods, you will need to
specify what EPG values are inputted through named arguments (e.g. `T2 = your.vector`), otherwise an error
message will be displayed.

The logical argument `compute.CI` allows for the computation of a confidence interval (95% by
default) for individual-based methods (cf. Cabaret & Berrag, 2004)

```{r simple FECR}
# Calculation of FECR values according to different methods
FECR(T1.mean,T2.mean,method = "Kochapakdee")
FECR(T1,T2,C1,C2,method = "Dash")
FECR(T2 = T2.mean,C2 = C2.mean,method = "Coles")
FECR(T2 = T2,C2 = C2,method = "Coles")
FECR(T1,T2,method = "Cabaret1")
FECR(T1,T2,C1,C2,method = "Cabaret2")
FECR(T1,T2,C1,C2,method = "Cabaret2",compute.CI = TRUE)
FECR(T1,T2,C1,C2,method = "MacIntosh",compute.CI = TRUE)
```
### When sample size is uneven
The last included method, `"MacIntosh"`, is an improvement of the `"Cabaret2"` that:    

*  depends on the arbitrary pair-matchings of individuals in the control (C) and test (T) groups
*  cannot be applied to unequal sample-sizes without arbitrarily subset the larger group
    
```{r unequal samp FECR, error=TRUE}
# Generate random EPG values, in the case of unequal sample size
T1 <- rpois(60,100);T1.mean<- mean(T1)
T2 <- rpois(60,10);T2.mean<- mean(T2)
C1 <- rpois(50,100);C1.mean<- mean(C1)
C2 <- rpois(50,90);C2.mean<- mean(C2)

# Calculation of FECR values according to our sample-size unsensitive method
FECR(T1,T2,C1,C2,method = "Cabaret2",compute.CI = TRUE)
FECR(T1,T2,C1,C2,method = "MacIntosh")
FECR(T1,T2,C1,C2,method = "MacIntosh",compute.CI = TRUE)

```

# Why improve the method from Cabaret & Berrag (2004)?
The motivation that led us to propose an improvement over the individual method proposed by the
authors is that we identified the two pitfalls mentioned in the previous paragraph, i.e. the
arbitrary pair-matching and requirement of an even sample-size.

Hereafter, we demonstrate the issue from the paper's own toy example.

## EPG values import
```{r toy exp}
# Generate random EPG values, in the simple case of equal sample size
T1 <- c(450,1250,1700,900,2550,500,750,850,500)
T1.mean <- mean(T1)
T2 <- c(50,0,0,0,50,450,400,0,0)
T2.mean <- mean(T2)
C1 <- c(750,600,500,700,1000,700,300,1250,1050)
C1.mean <- mean(C1)
C2 <- c(540,400,1000,1750,350,600,900,550,450)
C2.mean <- mean(C2)
```

## FECR calculations
As expected, we find FECR values similar to what the authors report:
```{r toy FECR}
# Generate random EPG values, in the simple case of equal sample size
FECR(T1.mean,T2.mean,method = "Kochapakdee")            # 90% in the original paper
FECR(T1,T2,C1,C2,method = "Dash")                       # 90% in the original paper
FECR(T2 = T2.mean,C2 = C2.mean,method = "Coles")        # 86% in the original paper
FECR(T1,T2,method = "Cabaret1",compute.CI = TRUE)       # 83%(58-99%) in the original paper
FECR(T1,T2,C1,C2,method = "Cabaret2",compute.CI = TRUE) # 84%(51-97%) in the original paper

FECR(T1,T2,C1,C2,method = "MacIntosh",compute.CI = TRUE)
```
Our proposed method leads to a somewhat comparable value, albeit significantly lowered. We explain
more on this hereafter.


## Demonstration of the pit-falls
### The implicit arbitrary pair-matching


The toy-example's values only lead to the reported FECR when inputted in their specific order.
Shuffling this order is enough to change the FECR value:
```{r example pitfall 1}
set.seed(1000)
# shuffling T and C
new.T <- sample(1:length(T1))
new.C <- sample(1:length(C1))

T1.new <- T1[new.T]
T2.new <- T2[new.T]
C1.new <- C1[new.C]
C2.new <- C2[new.C]

# Recalculating FECRs
FECR(T1.new,T2.new,C1.new,C2.new,method = "Cabaret2",compute.CI = TRUE)
FECR(T1.new,T2.new,C1.new,C2.new,method = "MacIntosh",compute.CI = TRUE)
```
Note that shuffling obviously has not change EPG distribution in T and C groups:
```{r suffling effects 1}
summary(T1)
summary(T1.new)
summary(C2)
summary(C2.new)
```

And neither have methods based on group-averaged EPG
```{r suffling effects 2}
FECR(T1.new,T2.new,C1.new,C2.new,method = "Dash")                       # 90% in the original paper
FECR(T2 = T2.new,C2 = C2.new,method = "Coles")        # 86% in the original paper
```
More precisely, here is the bootstrapped distribution of the FECR value itself (not its confidence
interval), across several
reshuffling:

```{r pitfall 1 details}
library(ggplot2)
library(magrittr)

set.seed(9000)

# replicating the shuffling of T and C
FECR.shuffled <- replicate(
  n = 1000,
  simplify = FALSE,
  expr = {
    # shuffle
    new.T <- sample(1:length(T1))
    new.C <- sample(1:length(C1))
    
    T1.new <- T1[new.T]
    T2.new <- T2[new.T]
    C1.new <- C1[new.C]
    C2.new <- C2[new.C]

    #FECR calculations
    data.frame(
      method = c("Cabaret2","MacIntosh"),
      FECR = c(
        FECR(T1.new,T2.new,C1.new,C2.new,method = "Cabaret2",compute.CI = FALSE),
        FECR(T1.new,T2.new,C1.new,C2.new,method = "MacIntosh",compute.CI = FALSE)
      )
    )
  }
) %>% 
  do.call(rbind,.)
FECR.shuffled %>% 
  ggplot(aes(x = FECR,fill = method))+
  facet_grid(method~.,scales = "free")+
  geom_histogram(binwidth = 2,alpha = 80)+
  guides(fill = "none")+
  scale_x_continuous(limits = c(0,100))+
  theme_bw()
```

We can see that, depending on how individuals in T and C are paired, Cabaret & Berrag's method leads
to a FECR drawn from a bimodal distribution.

Our method consistently leads to a single FECR value, close to the mean of this distribution:
```{r pitfall 1 avg}
subset(FECR.shuffled,method == "MacIntosh") %>% .$FECR %>%  unique()
subset(FECR.shuffled,method == "Cabaret2") %>% .$FECR %>%  mean()
```

### Uneven sample sizes
Let's simulate upon this toy example an uneven sample size between the T and C groups by randomly removing 2 individuals from one, e.g. T.

Since the `"Cabaret2"` method relies on a summation across n individuals in both the T and C groups, this requires subsetting the larger group too by randomly removing 2 individuals. This isn't a requirement for our method, which will keep using all the individuals from C despite T having 2 individuals less.
```{r example pitfall 2,error=TRUE}
set.seed(9999)
# removing 2 individuals from T and C
new.T <- sample(1:length(T1),length(T1) - 2)
new.C <- sample(1:length(C1),length(C1) - 2)

T1.new <- T1[new.T]
T2.new <- T2[new.T]
C1.new <- C1[new.C]
C2.new <- C2[new.C]

# Recalculating FECRs
FECR(T1.new,T2.new,C1.new,C2.new,method = "Cabaret2",compute.CI = TRUE)
FECR(T1.new,T2.new,C1,C2,method = "Cabaret2",compute.CI = TRUE)
FECR(T1.new,T2.new,C1,C2,method = "MacIntosh",compute.CI = TRUE)
```

Again, if this is replicated many times, FECRs are impacted differently across the two methods:
```{r pitfall 2 details}
set.seed(777)

# replicating the shuffling of T and C
FECR.minus.2 <- replicate(
  n = 1000,
  simplify = FALSE,
  expr = {
    # shuffle
    new.T <- sample(1:length(T1),length(T1) - 2)
    new.C <- sample(1:length(C1),length(C1) - 2)
    
    T1.new <- T1[new.T]
    T2.new <- T2[new.T]
    C1.new <- C1[new.C]
    C2.new <- C2[new.C]
    
    #FECR calculations
    data.frame(
      method = c("Cabaret2","MacIntosh"),
      FECR = c(
        FECR(T1.new,T2.new,C1.new,C2.new,method = "Cabaret2",compute.CI = FALSE),
        FECR(T1.new,T2.new,C1,C2,method = "MacIntosh",compute.CI = FALSE)
      )
    )
  }
) %>% 
  do.call(rbind,.)
FECR.minus.2 %>% 
  ggplot(aes(x = FECR,fill = method))+
  facet_grid(method~.,scales = "free")+
  geom_histogram(binwidth = 2,alpha = 80)+
  guides(fill = "none")+
  scale_x_continuous(limits = c(0,100))+
  theme_bw()
```

Therefore, on top of using all the data available, our method also leads to more stable FECR values.

### What about confidence intervals?

The same processes of reshuffling or removing datapoints can be replicated to calculate the
stability of confidence intervals' boundaries:
```{r pitfall CI details}
set.seed(1234)

# replicating the shuffling of T and C
CI.shuffled <- replicate(
  n = 100,
  simplify = FALSE,
  expr = {
    # shuffle
    new.T <- sample(1:length(T1))
    new.C <- sample(1:length(C1))
    
    T1.new <- T1[new.T]
    T2.new <- T2[new.T]
    C1.new <- C1[new.C]
    C2.new <- C2[new.C]
    Cab <- FECR(T1.new,T2.new,C1.new,C2.new,method = "Cabaret2",
                          compute.CI = TRUE,pb = FALSE)
    Mac <- FECR(T1.new,T2.new,C1.new,C2.new,method = "MacIntosh",
                          compute.CI = TRUE,pb = FALSE)

    #FECR calculations
    data.frame(
      method = c("Cabaret2","MacIntosh"),
      FECR = c(Cab,Mac),
      lower = c(
        attr(Cab,"CI")[1],
        attr(Mac,"CI")[1]
      ),
      upper = c(
        attr(Cab,"CI")[2],
        attr(Mac,"CI")[2]
      )
    )
  }
) %>% 
  do.call(rbind,.) %>% 
  cbind(rep = factor(rep(1:100,each = 2)),.)
CI.shuffled %>% 
  ggplot(aes(method,FECR,colour = method,group = rep))+
  geom_linerange(aes(ymin = lower,ymax = upper),position = position_dodge(.9))+
  geom_point(position = position_dodge(.9))+
  guides(colour = "none")+
  theme_bw()
```

Our proposed method is designed to calculate a FECR value (and its confidence interval) that is unique for a given set of EPG values in T and C groups. The only slight variations observed regarding the boundaries of the confidence interval is attributable to the bootstrap's own random resampling.